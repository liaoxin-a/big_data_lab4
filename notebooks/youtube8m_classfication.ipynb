{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be2db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_sched\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015b4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LEN = 5\n",
    "BATCH_SIZE = 24\n",
    "NUM_FOLDS  = 10\n",
    "FEATURES_DIM    = 1152\n",
    "NUM_CLASSES     = 1000\n",
    "\n",
    "LEARNING_RATE   = 0.00011729283760398037\n",
    "WEIGHT_DECAY    = 0.0011412688966608406\n",
    "\n",
    "LR_FACTOR       = 0.1\n",
    "LR_PATIENCE     = 3\n",
    "LR_MINIMUM      = 3e-7\n",
    "LR_THRESHOLD    = 1e-3\n",
    "\n",
    "NUM_EPOCHS      = 25\n",
    "LOG_FREQ        = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00a2e8",
   "metadata": {},
   "source": [
    "# DATA analysis\n",
    "\n",
    "File descriptions\n",
    "frame-level data\n",
    "\n",
    "Total size of 1.53TB (Large file warning!)\n",
    "Each video has\n",
    "\n",
    "a. id: unique id for the video, in train set it is a YouTube video id, and in test/validation they are anonymized.\n",
    "\n",
    "b. labels: list of labels of that video. c. Each frame has rgb: float array of length 1024, d. Each frame has audio: float array of length 128\n",
    "\n",
    "A subset of the validation set videos are provided with segment-level labels. In addition to id, labels and the frame level features described above, they come with\n",
    "\n",
    "a. segment_start_times: list of segment start times. b. segment_end_times: list of segment end times. c. segment_labels: list of segment labels. d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.\n",
    "\n",
    "vocabulary.csv - the full data dictionary for label names and their descriptions\n",
    "\n",
    "IMPORTANT: In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498d05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test0397.tfrecord', 'test1553.tfrecord', 'test2108.tfrecord', 'test3134.tfrecord', 'train0024.tfrecord', 'train0052.tfrecord', 'train0259.tfrecord', 'train0267.tfrecord', 'train0455.tfrecord', 'train0523.tfrecord', 'train0638.tfrecord', 'train0676.tfrecord', 'train0701.tfrecord', 'train0780.tfrecord', 'train0797.tfrecord', 'train0842.tfrecord', 'train0876.tfrecord', 'train0955.tfrecord', 'train0965.tfrecord', 'train1116.tfrecord', 'train1169.tfrecord', 'train1210.tfrecord', 'train1219.tfrecord', 'train1395.tfrecord', 'train1644.tfrecord', 'train1704.tfrecord', 'train1769.tfrecord', 'train1831.tfrecord', 'train1932.tfrecord', 'train1937.tfrecord', 'train2094.tfrecord', 'train2164.tfrecord', 'train2394.tfrecord', 'train2501.tfrecord', 'train2517.tfrecord', 'train2525.tfrecord', 'train3043.tfrecord', 'train3115.tfrecord', 'train3182.tfrecord', 'train3343.tfrecord', 'train3432.tfrecord', 'train3489.tfrecord', 'train3731.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "data_path=r\"C:\\Users\\liaox\\yt8m\\dataset_ori\"\n",
    "data_listdir =os.listdir(data_path)\n",
    "print(data_listdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654bac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaox\\yt8m\\dataset\\train0024.tfrecord\n"
     ]
    }
   ],
   "source": [
    "frame_lvl_record = os.path.join(data_path,data_listdir[0])\n",
    "print(frame_lvl_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd6cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liaox\\AppData\\Local\\Temp\\ipykernel_21384\\3546995533.py:4: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Number of videos in this tfrecord:  16\n",
      "Number of labels in this tfrecord:  16\n"
     ]
    }
   ],
   "source": [
    "vid_ids = []\n",
    "labels = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(frame_lvl_record):\n",
    "    tf_example = tf.train.Example.FromString(example)\n",
    "    vid_ids.append(tf_example.features.feature['id']\n",
    "                   .bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "\n",
    "print('Number of videos in this tfrecord: ',len(vid_ids))\n",
    "print ('Number of labels in this tfrecord: ', len (labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cdadb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liaox\\anaconda3\\envs\\pytorch_new\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "feat_rgb = []\n",
    "feat_audio = []\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(frame_lvl_record):  \n",
    "    tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "    sess = tf.InteractiveSession()\n",
    "    rgb_frame = []\n",
    "    audio_frame = []\n",
    "    # iterate through frames\n",
    "    for i in range(n_frames):\n",
    "        rgb_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['rgb']\n",
    "                  .feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).numpy())\n",
    "        audio_frame.append(tf.cast(tf.decode_raw(\n",
    "                tf_seq_example.feature_lists.feature_list['audio']\n",
    "                  .feature[i].bytes_list.value[0],tf.uint8)\n",
    "                       ,tf.float32).numpy())\n",
    "        \n",
    "        \n",
    "    sess.close()\n",
    "    \n",
    "    feat_audio.append(audio_frame)\n",
    "    feat_rgb.append(rgb_frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989f6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first video has 215 frames\n"
     ]
    }
   ],
   "source": [
    "print('The first video has %d frames' %len(feat_rgb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d92cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>TrainVideoCount</th>\n",
       "      <th>KnowledgeGraphId</th>\n",
       "      <th>Name</th>\n",
       "      <th>WikiUrl</th>\n",
       "      <th>Vertical1</th>\n",
       "      <th>Vertical2</th>\n",
       "      <th>Vertical3</th>\n",
       "      <th>WikiDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>378135</td>\n",
       "      <td>/m/01jddz</td>\n",
       "      <td>Concert</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Concert</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A concert is a live music performance in front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>200813</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>Car</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Car</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A car is a wheeled, self-powered motor vehicle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>181579</td>\n",
       "      <td>/m/026bk</td>\n",
       "      <td>Dance</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dance</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dance is a performance art form consisting of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>135357</td>\n",
       "      <td>/m/02wbm</td>\n",
       "      <td>Food</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Food</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food is any substance consumed to provide nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>130835</td>\n",
       "      <td>/m/02vx4</td>\n",
       "      <td>Association football</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Association_foot...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Association football, more commonly known as f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  TrainVideoCount KnowledgeGraphId                  Name  \\\n",
       "0      3           378135        /m/01jddz               Concert   \n",
       "1      7           200813          /m/0k4j                   Car   \n",
       "2      8           181579         /m/026bk                 Dance   \n",
       "3     11           135357         /m/02wbm                  Food   \n",
       "4     12           130835         /m/02vx4  Association football   \n",
       "\n",
       "                                             WikiUrl             Vertical1  \\\n",
       "0              https://en.wikipedia.org/wiki/Concert  Arts & Entertainment   \n",
       "1                  https://en.wikipedia.org/wiki/Car      Autos & Vehicles   \n",
       "2                https://en.wikipedia.org/wiki/Dance  Arts & Entertainment   \n",
       "3                 https://en.wikipedia.org/wiki/Food          Food & Drink   \n",
       "4  https://en.wikipedia.org/wiki/Association_foot...                Sports   \n",
       "\n",
       "  Vertical2 Vertical3                                    WikiDescription  \n",
       "0       NaN       NaN  A concert is a live music performance in front...  \n",
       "1       NaN       NaN  A car is a wheeled, self-powered motor vehicle...  \n",
       "2       NaN       NaN  Dance is a performance art form consisting of ...  \n",
       "3       NaN       NaN  Food is any substance consumed to provide nutr...  \n",
       "4       NaN       NaN  Association football, more commonly known as f...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocabulary = pd.read_csv(r'C:\\Users\\liaox\\yt8m\\dataset\\vocabulary.csv')\n",
    "vocabulary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f707a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Index             1000 non-null   int64 \n",
      " 1   TrainVideoCount   1000 non-null   int64 \n",
      " 2   KnowledgeGraphId  1000 non-null   object\n",
      " 3   Name              988 non-null    object\n",
      " 4   WikiUrl           988 non-null    object\n",
      " 5   Vertical1         1000 non-null   object\n",
      " 6   Vertical2         153 non-null    object\n",
      " 7   Vertical3         12 non-null     object\n",
      " 8   WikiDescription   988 non-null    object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "vocabulary.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957cbe66",
   "metadata": {},
   "source": [
    "# convert data to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a4e7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(prefix: str, wildcard: str) -> None:\n",
    "    print('converting', wildcard)\n",
    "    all_files = sorted(glob(wildcard))\n",
    "\n",
    "    all_ids = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "    all_features_list = []\n",
    "\n",
    "    for tfrec_file in all_files:\n",
    "        for example in tf.python_io.tf_record_iterator(tfrec_file):\n",
    "            tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "            video_id = tf_example.features.feature['id'] \\\n",
    "                       .bytes_list.value[0].decode(encoding='utf-8')\n",
    "\n",
    "            seg_start = list(tf_example.features.feature['segment_start_times'].int64_list.value)\n",
    "            seg_labels = list(tf_example.features.feature['segment_labels'].int64_list.value)\n",
    "            seg_scores = list(tf_example.features.feature['segment_scores'].float_list.value)\n",
    "\n",
    "            tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "            num_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "\n",
    "            if any(np.array(seg_start) > num_frames): # why are there videos with invalid labels?\n",
    "                print('skipping video', video_id, 'file', tfrec_file)\n",
    "                continue\n",
    "\n",
    "            for segment, label, score in zip(seg_start, seg_labels, seg_scores):\n",
    "                features = []\n",
    "\n",
    "                for frame in range(segment, segment + SEGMENT_LEN):\n",
    "                    rgb = tf.decode_raw(tf_seq_example.feature_lists \\\n",
    "                                        .feature_list['rgb'].feature[frame] \\\n",
    "                                        .bytes_list.value[0],tf.uint8).numpy()\n",
    "                    audio = tf.decode_raw(tf_seq_example.feature_lists \\\n",
    "                                          .feature_list['audio'].feature[frame] \\\n",
    "                                          .bytes_list.value[0],tf.uint8).numpy()\n",
    "\n",
    "                    frame_features = np.concatenate([rgb, audio])\n",
    "                    features.append(frame_features)\n",
    "\n",
    "                all_ids.append(video_id)\n",
    "                all_labels.append(label)\n",
    "                all_scores.append(score)\n",
    "                all_features_list.append(np.expand_dims(features, axis=0))\n",
    "\n",
    "\n",
    "    all_features = np.concatenate(all_features_list)\n",
    "    print(all_features.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #------labels\n",
    "    labels_table = pd.read_csv(r'C:\\Users\\liaox\\yt8m_ml\\code\\youtube-8m\\vocabulary.csv')\n",
    "    labels_table = labels_table.Index#len=1000\n",
    "\n",
    "    encode_table = np.zeros(np.amax(labels_table) + 1, dtype=int)#(1832)\n",
    "    for i, index in enumerate(labels_table):\n",
    "        encode_table[index] = i\n",
    "\n",
    "\n",
    "    labels = encode_table[all_labels]\n",
    "    #-------\n",
    "\n",
    "    \n",
    "    features_path=os.path.join(data_path, f'{prefix}_features.npy')\n",
    "    print('writing features to the disk,',features_path)\n",
    "    np.save(features_path, all_features)\n",
    "\n",
    "    \n",
    "    ids_path=os.path.join(data_path, f'{prefix}_ids.csv')\n",
    "    print('writing labels to the disk,',ids_path)\n",
    "    id_table=pd.DataFrame({'all_ids':all_ids,'all_labels':all_labels,'all_scores':all_scores,'labels':labels})\n",
    "    id_table.to_csv(ids_path,index=False,sep=',')\n",
    "\n",
    "\n",
    "    return features_path,ids_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba4c46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0024.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0052.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0259.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0267.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0455.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0523.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0638.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0676.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0701.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0780.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0797.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0842.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0876.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0955.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train0965.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1116.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1169.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1210.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1219.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1395.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1644.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1704.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1769.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1831.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1932.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train1937.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2094.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2164.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2394.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2501.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2517.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train2525.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3043.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3115.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3182.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3343.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3432.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3489.tfrecord', 'C:\\\\Users\\\\liaox\\\\yt8m\\\\dataset\\\\train3731.tfrecord']\n",
      "converting C:\\Users\\liaox\\yt8m\\dataset\\train*.tfrecord\n",
      "(2469, 5, 1152)\n",
      "writing features to the disk, C:\\Users\\liaox\\yt8m\\dataset\\train_features.npy\n",
      "writing labels to the disk, C:\\Users\\liaox\\yt8m\\dataset\\train_ids.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_tfrecord=r\"C:\\Users\\liaox\\yt8m\\dataset\\train*.tfrecord\"\n",
    "print(glob(train_tfrecord))\n",
    "features_path,ids_path=convert_data('train',train_tfrecord )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6e03564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "(314, 5, 1152)\n"
     ]
    }
   ],
   "source": [
    "#tmp\n",
    "# all_features_list=[np.zeros((1,5,1152))]*314\n",
    "# print(len(all_features_list))\n",
    "# all_features = np.concatenate(all_features_list)\n",
    "# print(all_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd182d",
   "metadata": {},
   "source": [
    "## load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d3755eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  all_ids  all_labels  all_scores  labels\n",
      "0    5way         316         1.0     167\n",
      "1    5way         316         1.0     167\n",
      "2    5way         316         1.0     167\n",
      "3    5way         316         1.0     167\n",
      "4    5way         316         1.0     167\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(ids_path) \n",
    "print(df.head(5))\n",
    "all_ids, all_labels, all_scores,labels = df['all_ids'],df['all_labels'],df['all_scores'],df['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69bc0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dequantize(feat_vector: np.array, max_quantized_value=2, min_quantized_value=-2) -> np.array:\n",
    "    ''' Dequantize the feature from the byte format to the float format. '''\n",
    "    assert max_quantized_value > min_quantized_value\n",
    "    quantized_range = max_quantized_value - min_quantized_value\n",
    "    scalar = quantized_range / 255.0\n",
    "    bias = (quantized_range / 512.0) + min_quantized_value\n",
    "    return feat_vector * scalar + bias\n",
    "\n",
    "\n",
    "# PyTorch dataset class for numpy arrays.\n",
    "class SegmentsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids: np.array, dataset_mask: Optional[np.array], labels: Optional[np.array],\n",
    "                 scores: Optional[np.array], features_path: str, mode: str) -> None:\n",
    "        print(f'creating SegmentsDataset in mode {mode}')\n",
    "\n",
    "        self.ids = ids\n",
    "        self.scores = scores\n",
    "        self.mode = mode\n",
    "        self.labels = labels\n",
    "\n",
    "        if self.mode != 'test':\n",
    "\n",
    "            assert dataset_mask is not None and self.scores is not None\n",
    "            self.features_indices = np.arange(dataset_mask.size)[dataset_mask]\n",
    "            \n",
    "            features_size = dataset_mask.size\n",
    "\n",
    "            assert self.labels.shape[0] == self.scores.shape[0]\n",
    "            assert self.features_indices.size == self.labels.shape[0]\n",
    "            assert features_size >= self.scores.shape[0]\n",
    "\n",
    "            if self.mode == 'train':\n",
    "                self.labels *= (self.scores > 0.5).astype(int)\n",
    "        else:\n",
    "            features_size = self.ids.shape[0]\n",
    "\n",
    "        self.features = np.load(features_path)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        features = self.features\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            features_indices = self.features_indices\n",
    "            labels = self.labels\n",
    "\n",
    "            x = features[features_indices[index]]\n",
    "        else:\n",
    "            x = features[index]\n",
    "\n",
    "        x = dequantize(x)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x, 0\n",
    "        else:\n",
    "            y = labels[index].item()\n",
    "            return x, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.ids.shape[0]\n",
    "\n",
    "\n",
    "def get_train_val_split(items: List[str], fold: int) -> Tuple[np.array, np.array]:\n",
    "    skf = KFold(NUM_FOLDS, shuffle=True, random_state=0)\n",
    "    items = np.array(items)\n",
    "    train_idx, val_idx = list(skf.split(items))[fold]\n",
    "    return items[train_idx], items[val_idx]\n",
    "\n",
    "def load_train_data(fold: int) -> Any:\n",
    "    df=pd.read_csv(ids_path) \n",
    "    all_ids, all_labels, all_scores,all_labels_index = df['all_ids'],df['all_labels'],df['all_scores'],df['labels']\n",
    "\n",
    "    unique_ids = sorted(set(all_ids))\n",
    "    unique_train_ids, unique_val_ids = get_train_val_split(unique_ids, fold)\n",
    "\n",
    "    all_ids = np.array(all_ids)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_scores = np.array(all_scores)\n",
    "    all_labels_index = np.array(all_labels_index)\n",
    "    print(all_ids.shape)\n",
    "    print(all_labels.shape)\n",
    "\n",
    "    train_mask = np.isin(all_ids, unique_train_ids)\n",
    "    train_ids = all_ids[train_mask]\n",
    "    train_labels = all_labels[train_mask]\n",
    "    train_scores = all_scores[train_mask]\n",
    "    train_labels_index=all_labels_index[train_mask]\n",
    "\n",
    "    val_ids = all_ids[~train_mask]\n",
    "    val_labels = all_labels[~train_mask]\n",
    "    val_scores = all_scores[~train_mask]\n",
    "    val_labels_index=all_labels_index[~train_mask]\n",
    "\n",
    "    train_dataset = SegmentsDataset(train_ids, train_mask, train_labels_index, train_scores,\n",
    "                                    features_path, mode='train')\n",
    "\n",
    "    val_dataset = SegmentsDataset(val_ids, ~train_mask, val_labels_index, val_scores,\n",
    "                                    features_path, mode='val')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=0, drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=0, drop_last=False)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75f94ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469,)\n",
      "(2469,)\n",
      "creating SegmentsDataset in mode train\n",
      "creating SegmentsDataset in mode val\n"
     ]
    }
   ],
   "source": [
    "fold_num=0\n",
    "train_loader, val_loader = load_train_data(fold_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70f87b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1050669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwishActivation(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigmoid(x) * x\n",
    "\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        width = FEATURES_DIM\n",
    "\n",
    "        for num_neurons in [2765, 1662]:\n",
    "            layers.append(nn.Linear(width, num_neurons))\n",
    "            width = num_neurons\n",
    "\n",
    "            layers.append(nn.BatchNorm1d(width))\n",
    "            layers.append(SwishActivation())\n",
    "\n",
    "        layers.append(nn.Linear(width, NUM_CLASSES))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.avg_pool(x).view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b33d2b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1152, out_features=2765, bias=True)\n",
       "    (1): BatchNorm1d(2765, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SwishActivation(\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (3): Linear(in_features=2765, out_features=1662, bias=True)\n",
       "    (4): BatchNorm1d(1662, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): SwishActivation(\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (6): Linear(in_features=1662, out_features=1000, bias=True)\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3bb93",
   "metadata": {},
   "source": [
    "## criterion,optimizer,lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14bbf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "lr_scheduler = lr_sched.ReduceLROnPlateau(optimizer, mode='max', factor=LR_FACTOR,\n",
    "                                    patience=LR_PATIENCE, threshold=LR_THRESHOLD,\n",
    "                                    min_lr=LR_MINIMUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e5044",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd4f25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def average_precision(actuals, predictions, k=None):\n",
    "    num_positives = actuals.sum() + 1e-10\n",
    "\n",
    "    sorted_idx = np.argsort(predictions)[::-1]\n",
    "    if k is not None:\n",
    "        sorted_idx = sorted_idx[:k]\n",
    "\n",
    "    actuals = actuals[sorted_idx]\n",
    "    precisions = np.cumsum(actuals) / np.arange(1, len(actuals) + 1)\n",
    "\n",
    "    return (precisions * actuals).sum() / float(num_positives)\n",
    "\n",
    "def get_model_path(fold_num: int) -> str:\n",
    "    return os.path.join(r'C:\\Users\\liaox\\yt8m',f'best_model_fold_{fold_num}.pth')\n",
    "\n",
    "class MeanAveragePrecisionCalculator:\n",
    "    ''' Classwise MAP@K - metric for Youtube-8M 2019 competition. '''\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASSES, k=10 ** 5):\n",
    "        self._num_classes = num_classes\n",
    "        self._k = k\n",
    "        self._predictions = [[] for _ in range(num_classes)]\n",
    "        self._actuals = [[] for _ in range(num_classes)]\n",
    "\n",
    "    def accumulate(self, predictions, actuals, masks=None):\n",
    "        if masks is None:\n",
    "            masks = np.ones_like(actuals)\n",
    "\n",
    "        for i in range(self._num_classes):\n",
    "            mask = masks[:, i] > 0\n",
    "\n",
    "            self._predictions[i].append(predictions[:, i][mask])\n",
    "            self._actuals[i].append(actuals[:, i][mask])\n",
    "\n",
    "    def __call__(self):\n",
    "        aps = []\n",
    "        positive_count = []\n",
    "        total_count = []\n",
    "\n",
    "        for i in range(self._num_classes):\n",
    "            actuals = np.concatenate(self._actuals[i])\n",
    "            predictions = np.concatenate(self._predictions[i])\n",
    "\n",
    "            aps.append(average_precision(actuals, predictions, self._k))\n",
    "\n",
    "            total_count.append(len(actuals))\n",
    "            positive_count.append(actuals.sum())\n",
    "\n",
    "        return np.mean(aps)\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    ''' Computes and stores the average and current value. '''\n",
    "    def __init__(self) -> None:\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val: float, n: int = 1) -> None:\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def set_lr(optimizer: Any, lr: float) -> None:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_lr(optimizer: Any) -> float:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = float(param_group['lr'])\n",
    "        return lr\n",
    "\n",
    "    assert False\n",
    "\n",
    "\n",
    "def accuracy(predicts: Any, targets: Any) -> float:\n",
    "    if isinstance(predicts, torch.Tensor):\n",
    "        predicts = predicts.cpu().numpy()\n",
    "\n",
    "    if isinstance(targets, torch.Tensor):\n",
    "        targets = targets.cpu().numpy()\n",
    "\n",
    "    if len(predicts.shape) == 2:\n",
    "        predicts = np.argmax(predicts, axis=1)\n",
    "\n",
    "    if len(targets.shape) == 2:\n",
    "        targets = np.argmax(targets, axis=1)\n",
    "\n",
    "    if predicts.shape != targets.shape:\n",
    "        print(predicts.shape)\n",
    "        print(targets.shape)\n",
    "        assert False\n",
    "\n",
    "    return np.mean(predicts == targets)\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(train_loader: Any, model: Any, criterion: Any, optimizer: Any,\n",
    "                epoch: int, lr_scheduler: Any) -> float:\n",
    "    print(f'epoch: {epoch}')\n",
    "    print(f'learning rate: {get_lr(optimizer)}')\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    avg_score = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    num_steps = len(train_loader)\n",
    "\n",
    "    # print(f'total batches: {num_steps}')\n",
    "    end = time.time()\n",
    "    activation = nn.Softmax(dim=1)\n",
    "\n",
    "    for i, (input_, target) in enumerate(train_loader):\n",
    "        input_ = input_.cuda()\n",
    "        output = model(input_)\n",
    "\n",
    "        loss = criterion(output, target.cuda())\n",
    "\n",
    "        predict = torch.argmax(output.detach(), dim=-1)\n",
    "        avg_score.update(accuracy(predict, target))\n",
    "\n",
    "        losses.update(loss.data.item(), input_.size(0))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % LOG_FREQ == 0:\n",
    "            print(f'{epoch} [{i}/{num_steps}]\\t'\n",
    "                        f'time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        f'loss {losses.val:.4f} ({losses.avg:.4f})\\t'\n",
    "                        f'acc {avg_score.val:.4f} ({avg_score.avg:.4f})')\n",
    "\n",
    "    print(f' * average acc on train {avg_score.avg:.4f}')\n",
    "    return avg_score.avg\n",
    "\n",
    "\n",
    "\n",
    "def get_lr(optimizer: Any) -> float:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = float(param_group['lr'])\n",
    "        return lr\n",
    "\n",
    "    assert False\n",
    "\n",
    "\n",
    "def set_lr(optimizer: Any, lr: float) -> None:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "\n",
    "\n",
    "def inference(data_loader: Any, model: Any) -> np.array:\n",
    "    ''' Returns predictions array. '''\n",
    "    model.eval()\n",
    "\n",
    "    predicts_list = []\n",
    "    activation = nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_, target in data_loader:\n",
    "            output = model(input_.cuda())\n",
    "            output = activation(output)\n",
    "            predicts_list.append(output.detach().cpu().numpy())\n",
    "\n",
    "    predicts = np.concatenate(predicts_list)\n",
    "    print('predicts', predicts.shape)\n",
    "    return predicts\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader: Any, model: Any, epoch: int) -> float:\n",
    "    ''' Infers predictions and calculates validation score. '''\n",
    "    print('validate()')\n",
    "    val_pred = inference(val_loader, model)\n",
    "\n",
    "    metric = MeanAveragePrecisionCalculator()\n",
    "\n",
    "    val_true = val_loader.dataset.labels\n",
    "    val_scores = val_loader.dataset.scores\n",
    "\n",
    "    assert val_true.size == val_pred.shape[0]\n",
    "\n",
    "    masks = np.eye(NUM_CLASSES)[val_true]   # convert to one-hot encoding\n",
    "    actuals = masks * np.expand_dims(val_scores, axis=-1)\n",
    "\n",
    "    metric.accumulate(val_pred, actuals, masks)\n",
    "    score = metric()\n",
    "\n",
    "    print(f' * epoch {epoch} validation score: {score:.4f}')\n",
    "    return score\n",
    "\n",
    "def train_model(model,criterion,optimizer,train_loader, val_loader) -> float:\n",
    "    print('=' * 80)\n",
    "\n",
    "    last_epoch = -1\n",
    "    print(f'training will start from epoch {last_epoch + 1}')\n",
    "\n",
    "    best_score = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    last_lr = get_lr(optimizer)\n",
    "    best_model_path = None\n",
    "\n",
    "    for epoch in range(last_epoch + 1, NUM_EPOCHS):\n",
    "        print('-' * 50)\n",
    "        lr = get_lr(optimizer)\n",
    "\n",
    "        # if we have just reduced LR, reload the best saved model\n",
    "        if lr < last_lr - 1e-10 and best_model_path is not None:\n",
    "            print(f'learning rate dropped: {lr}, reloading')\n",
    "            last_checkpoint = torch.load(best_model_path)\n",
    "\n",
    "            model.load_state_dict(last_checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(last_checkpoint['optimizer'])\n",
    "            print(f'checkpoint loaded: {best_model_path}')\n",
    "            set_lr(optimizer, lr)\n",
    "            last_lr = lr\n",
    "\n",
    "        train_epoch(train_loader, model, criterion, optimizer, epoch, lr_scheduler)\n",
    "        score = validate(val_loader, model, epoch)\n",
    "\n",
    "        lr_scheduler.step(metrics=score)\n",
    "\n",
    "        is_best = score > best_score\n",
    "        best_score = max(score, best_score)\n",
    "        if is_best:\n",
    "            best_epoch = epoch\n",
    "\n",
    "        if is_best:\n",
    "            best_model_path = get_model_path(fold_num)\n",
    "\n",
    "            data_to_save = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }\n",
    "\n",
    "            torch.save(data_to_save, best_model_path)\n",
    "            print(f'a snapshot was saved to {best_model_path}')\n",
    "\n",
    "    print(f'best score: {best_score:.04f}')\n",
    "    return -best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7adccc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "training will start from epoch 0\n",
      "--------------------------------------------------\n",
      "epoch: 0\n",
      "learning rate: 0.00011729283760398037\n",
      "total batches: 92\n",
      "0 [0/92]\ttime 3.896 (3.896)\tloss 6.9039 (6.9039)\tacc 0.0000 (0.0000)\n",
      " * average acc on train 0.4706\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 0 validation score: 0.0334\n",
      "a snapshot was saved to C:\\Users\\liaox\\yt8m\\best_model_fold_0.pth\n",
      "--------------------------------------------------\n",
      "epoch: 1\n",
      "learning rate: 0.00011729283760398037\n",
      "total batches: 92\n",
      "1 [0/92]\ttime 0.005 (0.005)\tloss 1.4420 (1.4420)\tacc 0.8333 (0.8333)\n",
      " * average acc on train 0.8197\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 1 validation score: 0.0323\n",
      "--------------------------------------------------\n",
      "epoch: 2\n",
      "learning rate: 0.00011729283760398037\n",
      "total batches: 92\n",
      "2 [0/92]\ttime 0.005 (0.005)\tloss 0.4533 (0.4533)\tacc 0.9583 (0.9583)\n",
      " * average acc on train 0.9216\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 2 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 3\n",
      "learning rate: 0.00011729283760398037\n",
      "total batches: 92\n",
      "3 [0/92]\ttime 0.005 (0.005)\tloss 0.2186 (0.2186)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.9624\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 3 validation score: 0.0319\n",
      "--------------------------------------------------\n",
      "epoch: 4\n",
      "learning rate: 0.00011729283760398037\n",
      "total batches: 92\n",
      "4 [0/92]\ttime 0.005 (0.005)\tloss 0.0797 (0.0797)\tacc 1.0000 (1.0000)\n",
      " * average acc on train 0.9778\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 4 validation score: 0.0328\n",
      "--------------------------------------------------\n",
      "learning rate dropped: 1.1729283760398038e-05, reloading\n",
      "checkpoint loaded: C:\\Users\\liaox\\yt8m\\best_model_fold_0.pth\n",
      "epoch: 5\n",
      "learning rate: 1.1729283760398038e-05\n",
      "total batches: 92\n",
      "5 [0/92]\ttime 0.007 (0.007)\tloss 1.1934 (1.1934)\tacc 0.8750 (0.8750)\n",
      " * average acc on train 0.8342\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 5 validation score: 0.0324\n",
      "--------------------------------------------------\n",
      "epoch: 6\n",
      "learning rate: 1.1729283760398038e-05\n",
      "total batches: 92\n",
      "6 [0/92]\ttime 0.006 (0.006)\tloss 1.5173 (1.5173)\tacc 0.8333 (0.8333)\n",
      " * average acc on train 0.8514\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 6 validation score: 0.0322\n",
      "--------------------------------------------------\n",
      "epoch: 7\n",
      "learning rate: 1.1729283760398038e-05\n",
      "total batches: 92\n",
      "7 [0/92]\ttime 0.006 (0.006)\tloss 1.0834 (1.0834)\tacc 0.7500 (0.7500)\n",
      " * average acc on train 0.8596\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 7 validation score: 0.0328\n",
      "--------------------------------------------------\n",
      "epoch: 8\n",
      "learning rate: 1.1729283760398038e-05\n",
      "total batches: 92\n",
      "8 [0/92]\ttime 0.006 (0.006)\tloss 0.8458 (0.8458)\tacc 0.9583 (0.9583)\n",
      " * average acc on train 0.8750\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 8 validation score: 0.0322\n",
      "--------------------------------------------------\n",
      "learning rate dropped: 1.1729283760398038e-06, reloading\n",
      "checkpoint loaded: C:\\Users\\liaox\\yt8m\\best_model_fold_0.pth\n",
      "epoch: 9\n",
      "learning rate: 1.1729283760398038e-06\n",
      "total batches: 92\n",
      "9 [0/92]\ttime 0.005 (0.005)\tloss 1.4878 (1.4878)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8324\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 9 validation score: 0.0328\n",
      "--------------------------------------------------\n",
      "epoch: 10\n",
      "learning rate: 1.1729283760398038e-06\n",
      "total batches: 92\n",
      "10 [0/92]\ttime 0.005 (0.005)\tloss 1.6482 (1.6482)\tacc 0.8333 (0.8333)\n",
      " * average acc on train 0.8351\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 10 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 11\n",
      "learning rate: 1.1729283760398038e-06\n",
      "total batches: 92\n",
      "11 [0/92]\ttime 0.005 (0.005)\tloss 1.2339 (1.2339)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8374\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 11 validation score: 0.0326\n",
      "--------------------------------------------------\n",
      "epoch: 12\n",
      "learning rate: 1.1729283760398038e-06\n",
      "total batches: 92\n",
      "12 [0/92]\ttime 0.005 (0.005)\tloss 1.4351 (1.4351)\tacc 0.8750 (0.8750)\n",
      " * average acc on train 0.8338\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 12 validation score: 0.0325\n",
      "--------------------------------------------------\n",
      "learning rate dropped: 3e-07, reloading\n",
      "checkpoint loaded: C:\\Users\\liaox\\yt8m\\best_model_fold_0.pth\n",
      "epoch: 13\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "13 [0/92]\ttime 0.006 (0.006)\tloss 1.5314 (1.5314)\tacc 0.8750 (0.8750)\n",
      " * average acc on train 0.8306\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 13 validation score: 0.0328\n",
      "--------------------------------------------------\n",
      "epoch: 14\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "14 [0/92]\ttime 0.008 (0.008)\tloss 1.3641 (1.3641)\tacc 0.9583 (0.9583)\n",
      " * average acc on train 0.8347\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 14 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 15\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "15 [0/92]\ttime 0.006 (0.006)\tloss 1.2646 (1.2646)\tacc 0.8750 (0.8750)\n",
      " * average acc on train 0.8383\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 15 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 16\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "16 [0/92]\ttime 0.006 (0.006)\tloss 0.8687 (0.8687)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8383\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 16 validation score: 0.0326\n",
      "--------------------------------------------------\n",
      "epoch: 17\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "17 [0/92]\ttime 0.005 (0.005)\tloss 1.6919 (1.6919)\tacc 0.8333 (0.8333)\n",
      " * average acc on train 0.8338\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 17 validation score: 0.0329\n",
      "--------------------------------------------------\n",
      "epoch: 18\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "18 [0/92]\ttime 0.006 (0.006)\tloss 1.5222 (1.5222)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8406\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 18 validation score: 0.0326\n",
      "--------------------------------------------------\n",
      "epoch: 19\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "19 [0/92]\ttime 0.006 (0.006)\tloss 1.6618 (1.6618)\tacc 0.7500 (0.7500)\n",
      " * average acc on train 0.8397\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 19 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 20\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "20 [0/92]\ttime 0.006 (0.006)\tloss 1.2704 (1.2704)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8433\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 20 validation score: 0.0324\n",
      "--------------------------------------------------\n",
      "epoch: 21\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "21 [0/92]\ttime 0.005 (0.005)\tloss 1.4329 (1.4329)\tacc 0.7917 (0.7917)\n",
      " * average acc on train 0.8361\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 21 validation score: 0.0325\n",
      "--------------------------------------------------\n",
      "epoch: 22\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "22 [0/92]\ttime 0.006 (0.006)\tloss 1.8637 (1.8637)\tacc 0.7500 (0.7500)\n",
      " * average acc on train 0.8302\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 22 validation score: 0.0325\n",
      "--------------------------------------------------\n",
      "epoch: 23\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "23 [0/92]\ttime 0.006 (0.006)\tloss 1.3133 (1.3133)\tacc 0.9167 (0.9167)\n",
      " * average acc on train 0.8365\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 23 validation score: 0.0327\n",
      "--------------------------------------------------\n",
      "epoch: 24\n",
      "learning rate: 3e-07\n",
      "total batches: 92\n",
      "24 [0/92]\ttime 0.006 (0.006)\tloss 2.1532 (2.1532)\tacc 0.6667 (0.6667)\n",
      " * average acc on train 0.8410\n",
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch 24 validation score: 0.0326\n",
      "best score: 0.0334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.03341651785601382"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model,criterion,optimizer,train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5d78dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate()\n",
      "predicts (244, 1000)\n",
      " * epoch end validation score: 0.0326\n"
     ]
    }
   ],
   "source": [
    "epoch='end'\n",
    "score = validate(val_loader, model, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39527e",
   "metadata": {},
   "source": [
    "## predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df08d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_video(video_dict):\n",
    "    return (\n",
    "        video_dict['id'],\n",
    "        video_dict['labels'],\n",
    "        video_dict['features'],\n",
    "        video_dict['segment_start_times'],\n",
    "        video_dict['segment_labels'],\n",
    "        video_dict['segment_scores']\n",
    "    )\n",
    "\n",
    "def wrap_segment(vid, labels, start_time, features, segment_label, segment_score):\n",
    "    return {\n",
    "        'id': vid,\n",
    "        'labels': labels,\n",
    "        'start_time': start_time,\n",
    "        'features': features,\n",
    "        'segment_label': segment_label,\n",
    "        'segment_score': segment_score\n",
    "    }\n",
    "\n",
    "class YouTube8MRecordParser:\n",
    "    context_features = {\n",
    "        \"id\": tf.io.FixedLenFeature((), tf.string),\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"segment_start_times\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"segment_end_times\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"segment_labels\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"segment_scores\": tf.io.VarLenFeature(tf.float32)\n",
    "    }\n",
    "\n",
    "    sequence_features = {\n",
    "        \"rgb\": tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "        \"audio\": tf.io.FixedLenSequenceFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(proto):\n",
    "        sample, sequence_parsed = tf.io.parse_single_sequence_example(\n",
    "            proto,\n",
    "            YouTube8MRecordParser.context_features,\n",
    "            YouTube8MRecordParser.sequence_features\n",
    "        )\n",
    "\n",
    "        sample['features'] = tf.concat([\n",
    "            tf.decode_raw(sequence_parsed['rgb'], tf.uint8),\n",
    "            tf.decode_raw(sequence_parsed['audio'], tf.uint8)\n",
    "        ], axis=-1\n",
    "        )\n",
    "\n",
    "        for k, v in sample.items():\n",
    "            if k == 'labels' or 'segment' in k:\n",
    "                sample[k] = v.values\n",
    "\n",
    "        return sample\n",
    "\n",
    "    @staticmethod\n",
    "    def to_numpy(eager_sample):\n",
    "        return {\n",
    "            k: v.numpy()\n",
    "            for k, v in eager_sample.items()\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_video_dataset(tfrecords, num_workers=None):\n",
    "        return tf.data.TFRecordDataset(tfrecords, num_parallel_reads=num_workers)\\\n",
    "            .map(YouTube8MRecordParser.parse, num_parallel_calls=num_workers)\\\n",
    "            .filter(lambda video: tf.math.greater_equal(tf.shape(video['features'])[0], 5))\n",
    "\n",
    "    @staticmethod\n",
    "    def _video_to_segments_iterator(vid, labels, features, segment_start_times, segment_labels, segment_scores):\n",
    "        n_samples = len(features) // SEGMENT_LEN\n",
    "\n",
    "        assert n_samples >= 5\n",
    "\n",
    "        for idx in range(n_samples):\n",
    "            start_time = SEGMENT_LEN * idx\n",
    "\n",
    "            segment_label = segment_score = -1\n",
    "            if start_time in segment_start_times:\n",
    "                i = np.where(segment_start_times == start_time)[0][0]\n",
    "                segment_label = segment_labels[i]\n",
    "                segment_score = segment_scores[i]\n",
    "\n",
    "            yield (\n",
    "                vid,\n",
    "                labels,\n",
    "                start_time,\n",
    "                features[start_time: start_time + SEGMENT_LEN],\n",
    "                segment_label,\n",
    "                np.float32(segment_score)\n",
    "            )\n",
    "\n",
    "    def _video_to_segments(*args):\n",
    "        result = [[] for _ in range(6)]\n",
    "\n",
    "        for segment in YouTube8MRecordParser._video_to_segments_iterator(*args):\n",
    "            for i, value in enumerate(segment):\n",
    "                result[i].append(value)\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_segment_dataset(tfrecords: List[str]) -> Any:\n",
    "        return YouTube8MRecordParser.get_video_dataset(tfrecords, None)\\\n",
    "            .map(lambda video: tf.py_func(\n",
    "                YouTube8MRecordParser._video_to_segments,\n",
    "                unwrap_video(video),\n",
    "                Tout=[tf.string, tf.int64, tf.int32, tf.uint8, tf.int32, tf.float32]),\n",
    "                num_parallel_calls=None\n",
    "            )\\\n",
    "            .flat_map(lambda *args: tf.data.Dataset.zip(tuple(\n",
    "                tf.data.Dataset.from_tensor_slices(k)\n",
    "                for k in args))\n",
    "            )\\\n",
    "            .map(\n",
    "                wrap_segment,\n",
    "                num_parallel_calls=None\n",
    "            )\n",
    "\n",
    "class YouTube8MSegmentDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, tfrecords: List[str]) -> None:\n",
    "        self._dataset = YouTube8MRecordParser.get_segment_dataset(tfrecords)\n",
    "\n",
    "    def __iter__(self) -> None:\n",
    "        for i, segment in enumerate(map(YouTube8MRecordParser.to_numpy, self._dataset)):\n",
    "            features = dequantize(segment['features']).astype(np.float32)\n",
    "            yield features, segment['id'].decode()\n",
    "\n",
    "def inference_for_testset(test_predicts: np.array, data_loader: Any, model: Any) -> np.array:\n",
    "    ''' Returns predictions array. '''\n",
    "    model.eval()\n",
    "\n",
    "    ids_list: List[str] = []\n",
    "    activation = nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input_, ids) in enumerate(data_loader):\n",
    "            output = model(input_.cuda())\n",
    "            output = activation(output)\n",
    "\n",
    "            ids_list.extend(ids)\n",
    "            pred = output.detach().cpu().numpy()\n",
    "            bs = data_loader.batch_size\n",
    "            test_predicts[i * bs : i * bs + pred.shape[0]] += pred\n",
    "\n",
    "    ids = np.array(ids_list)\n",
    "    print('ids', ids.shape)\n",
    "    return ids\n",
    "\n",
    "\n",
    "\n",
    "def load_test_data(wildcard: str) -> Any:\n",
    "    test_dataset = YouTube8MSegmentDataset(glob(wildcard))\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "575a8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liaox\\AppData\\Local\\Temp\\ipykernel_35688\\1660124887.py:108: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "test_loader = load_test_data(r'C:\\Users\\liaox\\yt8m_ml\\3\\frame\\test\\test*.tfrecord')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e16a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model,test_loader) -> np.array:\n",
    "    print(f'predicting on the test set')\n",
    "    test_predicts = np.zeros((2038114, 1000), dtype=np.float16)\n",
    "\n",
    "    output = inference_for_testset(test_predicts, test_loader, model)\n",
    "    return output,test_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "242466d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on the test set\n",
      "ids (1976,)\n"
     ]
    }
   ],
   "source": [
    "test_ids,test_predicts = predict_with_model(model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
